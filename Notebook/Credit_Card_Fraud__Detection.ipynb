{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc793eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# install required packages for the project\n",
    "!pip install -q scikit-learn pandas numpy imbalanced-learn matplotlib seaborn joblib shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee0265e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas, sklearn, imblearn versions: 2.3.3\n",
      "Loaded shape: (284807, 31)\n",
      "Class distribution (counts):\n",
      " Class\n",
      "0    284315\n",
      "1       492\n",
      "Name: count, dtype: int64\n",
      "Class distribution (proportions):\n",
      " Class\n",
      "0    0.998273\n",
      "1    0.001727\n",
      "Name: proportion, dtype: float64\n",
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9       V10       V11       V12       V13       V14  \\\n",
      "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
      "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
      "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
      "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
      "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
      "\n",
      "        V15       V16       V17       V18       V19       V20       V21  \\\n",
      "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
      "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
      "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
      "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
      "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
      "\n",
      "        V22       V23       V24       V25       V26       V27       V28  \\\n",
      "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
      "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
      "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
      "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
      "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
      "\n",
      "   Amount  Class  \n",
      "0  149.62      0  \n",
      "1    2.69      0  \n",
      "2  378.66      0  \n",
      "3  123.50      0  \n",
      "4   69.99      0  \n"
     ]
    }
   ],
   "source": [
    "# imports + load\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"pandas, sklearn, imblearn versions:\", pd.__version__)\n",
    "# Load dataset - change path if needed\n",
    "df = pd.read_csv(\"creditcard.csv\")\n",
    "print(\"Loaded shape:\", df.shape)\n",
    "print(\"Class distribution (counts):\\n\", df['Class'].value_counts())\n",
    "print(\"Class distribution (proportions):\\n\", df['Class'].value_counts(normalize=True))\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ad122bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      " Time    0\n",
      "V1      0\n",
      "V2      0\n",
      "V3      0\n",
      "V4      0\n",
      "V5      0\n",
      "V6      0\n",
      "V7      0\n",
      "V8      0\n",
      "V9      0\n",
      "V10     0\n",
      "V11     0\n",
      "V12     0\n",
      "V13     0\n",
      "V14     0\n",
      "V15     0\n",
      "V16     0\n",
      "V17     0\n",
      "V18     0\n",
      "V19     0\n",
      "dtype: int64\n",
      "After dropna shape: (284807, 31)\n"
     ]
    }
   ],
   "source": [
    "# cleaning + checks\n",
    "print(\"Missing values per column:\\n\", df.isnull().sum().sort_values(ascending=False).head(20))\n",
    "# If missing are negligible, drop them:\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "print(\"After dropna shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecb7b653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of behavioral columns:\n",
      "    user_id   device  login_hour  user_total_tx  session_count_24h  \\\n",
      "0      860  desktop           4             52                  1   \n",
      "1     3772   mobile          16             50                  1   \n",
      "2     3092   mobile          18             62                  2   \n",
      "3      466   tablet           5             52                  2   \n",
      "4     4426  desktop          15             58                  1   \n",
      "\n",
      "   device_change_count  \n",
      "0                    0  \n",
      "1                    0  \n",
      "2                    0  \n",
      "3                    0  \n",
      "4                    1  \n"
     ]
    }
   ],
   "source": [
    "# simulate behavior features (deterministic seed for reproducibility)\n",
    "np.random.seed(42)\n",
    "n = df.shape[0]\n",
    "\n",
    "# Simulate user_id: adjust n_users as desired\n",
    "n_users = 5000\n",
    "df['user_id'] = np.random.choice(np.arange(n_users), size=n)\n",
    "\n",
    "# Simulate device category distribution\n",
    "df['device'] = np.random.choice(['mobile','desktop','tablet'], size=n, p=[0.6,0.35,0.05])\n",
    "\n",
    "# Simulate login_hour (0-23). Optionally correlate fraud with late-night hours later.\n",
    "df['login_hour'] = np.random.randint(0,24,size=n)\n",
    "\n",
    "# Aggregate per user: user_total_tx\n",
    "user_counts = df['user_id'].value_counts().rename('user_total_tx')\n",
    "df = df.merge(user_counts, left_on='user_id', right_index=True)\n",
    "\n",
    "# session_count_24h: simulate based on user_total_tx\n",
    "df['session_count_24h'] = (np.random.poisson(1, size=n) + (df['user_total_tx'] > 5).astype(int))\n",
    "\n",
    "# device_change_count: small poisson noise + occasional changes\n",
    "df['device_change_count'] = np.random.poisson(0.2, size=n) + (np.random.rand(n) < 0.05).astype(int)\n",
    "\n",
    "print(\"Sample of behavioral columns:\\n\", df[['user_id','device','login_hour','user_total_tx','session_count_24h','device_change_count']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7b46d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features selected: 35\n",
      "First 20 features: ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20']\n",
      "Feature matrix shape: (284807, 35) Target shape: (284807,)\n"
     ]
    }
   ],
   "source": [
    "# encode categorical features\n",
    "# One-hot for device\n",
    "df = pd.get_dummies(df, columns=['device'], drop_first=True)\n",
    "\n",
    "# Label encode user_id for tree models (for sequence models we'll treat differently)\n",
    "le = LabelEncoder()\n",
    "df['user_id_enc'] = le.fit_transform(df['user_id'])\n",
    "\n",
    "# build features list (V1..V28, Time, Amount + behavioral features)\n",
    "features = [f\"V{i}\" for i in range(1,29)] + ['Time','Amount',\n",
    "            'session_count_24h','device_change_count','login_hour',\n",
    "            'device_desktop','device_tablet','user_id_enc']\n",
    "\n",
    "# keep only available cols to avoid errors\n",
    "features = [c for c in features if c in df.columns]\n",
    "print(\"Number of features selected:\", len(features))\n",
    "print(\"First 20 features:\", features[:20])\n",
    "X = df[features]\n",
    "y = df['Class'].astype(int)\n",
    "print(\"Feature matrix shape:\", X.shape, \"Target shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f3399bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled columns: ['Time', 'Amount']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shashwat\\AppData\\Local\\Temp\\ipykernel_23348\\2685350633.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[to_scale] = scaler.fit_transform(X[to_scale])\n"
     ]
    }
   ],
   "source": [
    "# scale Time and Amount\n",
    "scaler = StandardScaler()\n",
    "to_scale = [c for c in ['Time','Amount'] if c in X.columns]\n",
    "if to_scale:\n",
    "    X[to_scale] = scaler.fit_transform(X[to_scale])\n",
    "    print(\"Scaled columns:\", to_scale)\n",
    "else:\n",
    "    print(\"No Time/Amount found to scale.\")\n",
    "# Optionally persist scaler after training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
